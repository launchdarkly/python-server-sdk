from ldclient import operators
from ldclient.context import Context, _USER_STRING_ATTRS
from ldclient.evaluation import BigSegmentsStatus, EvaluationDetail
from ldclient.impl.event_factory import _EventFactory

import hashlib
import logging
from typing import Any, Callable, Dict, List, Optional, Tuple

# For consistency with past logging behavior, we are pretending that the evaluation logic still lives in
# the ldclient.evaluation module.
log = logging.getLogger('ldclient.flag')

__LONG_SCALE__ = float(0xFFFFFFFFFFFFFFF)

__BUILTINS__ = ["key", "secondary", "ip", "country", "email",
                "firstName", "lastName", "avatar", "name", "anonymous"]


def _context_to_user_dict(context: Context) -> dict:
    # temporary helper to allow us to update some parts of the SDK to use Context while others are
    # still using the user model
    ret = {'key': context.key}  # type: Dict[str, Any]
    if context.name is not None:
        ret['name'] = context.name
    if context.anonymous:
        ret['anonymous'] = True
    custom = None
    for attr in context.custom_attributes:
        if attr in _USER_STRING_ATTRS:
            ret[attr] = context.get(attr)
            continue
        if custom is None:
            custom = {}
        custom[attr] = context.get(attr)
    if custom is not None:
        ret['custom'] = custom
    private = list(context.private_attributes)
    if len(private) != 0:
        ret['privateAttributeNames'] = private
    return ret


# EvalResult is used internally to hold the EvaluationDetail result of an evaluation along with
# other side effects that are not exposed to the application, such as events generated by
# prerequisite evaluations, and the cached state of any Big Segments query that we may have
# ended up having to do for the context.
class EvalResult:
    def __init__(self):
        self.detail = None
        self.events = None
        self.big_segments_status = None
        self.big_segments_membership = None

    def add_event(self, event):
        if self.events is None:
            self.events = []
        self.events.append(event)


class Evaluator:
    """
    Encapsulates the feature flag evaluation logic. The Evaluator has no knowledge of the rest of the SDK environment;
    if it needs to retrieve flags or segments that are referenced by a flag, it does so through a read-only interface
    that is provided in the constructor. It also produces feature events as appropriate for any referenced prerequisite
    flags, but does not send them.
    """
    def __init__(
        self,
        get_flag: Callable[[str], Optional[dict]],
        get_segment: Callable[[str], Optional[dict]],
        get_big_segments_membership: Callable[[str], Tuple[Optional[dict], str]]
    ):
        """
        :param get_flag: function provided by LDClient that takes a flag key and returns either the flag or None
        :param get_segment: same as get_flag but for segments
        :param get_big_segments_membership: takes a context key (not a context hash) and returns a tuple of
            (membership, status) where membership is as defined in BigSegmentStore, and status is one
            of the BigSegmentStoreStatus constants
        """
        self.__get_flag = get_flag
        self.__get_segment = get_segment
        self.__get_big_segments_membership = get_big_segments_membership

    def evaluate(self, flag: dict, context: Context, event_factory: _EventFactory) -> EvalResult:
        state = EvalResult()
        state.detail = self._evaluate(flag, context, state, event_factory)
        if state.big_segments_status is not None:
            state.detail.reason['bigSegmentsStatus'] = state.big_segments_status
        return state

    def _evaluate(self, flag: dict, context: Context, state: EvalResult, event_factory: _EventFactory) -> EvaluationDetail:
        if not flag.get('on', False):
            return _get_off_value(flag, {'kind': 'OFF'})

        prereq_failure_reason = self._check_prerequisites(flag, context, state, event_factory)
        if prereq_failure_reason is not None:
            return _get_off_value(flag, prereq_failure_reason)

        # Check to see if any context targets match:
        target_result = self._check_targets(flag, context)
        if target_result is not None:
            return target_result

        # Now walk through the rules to see if any match
        for index, rule in enumerate(flag.get('rules') or []):
            if self._rule_matches_context(rule, context, state):
                return _get_value_for_variation_or_rollout(flag, rule, context,
                    {'kind': 'RULE_MATCH', 'ruleIndex': index, 'ruleId': rule.get('id')})

        # Walk through fallthrough and see if it matches
        return _get_value_for_variation_or_rollout(flag, flag['fallthrough'] or {}, context, {'kind': 'FALLTHROUGH'})

    def _check_prerequisites(self, flag: dict, context: Context, state: EvalResult, event_factory: _EventFactory) -> Optional[dict]:
        failed_prereq = None
        prereq_res = None
        for prereq in flag.get('prerequisites') or []:
            prereq_flag = self.__get_flag(prereq.get('key'))
            if prereq_flag is None:
                log.warning("Missing prereq flag: " + prereq.get('key'))
                failed_prereq = prereq
            else:
                prereq_res = self._evaluate(prereq_flag, context, state, event_factory)
                # Note that if the prerequisite flag is off, we don't consider it a match no matter what its
                # off variation was. But we still need to evaluate it in order to generate an event.
                if (not prereq_flag.get('on', False)) or prereq_res.variation_index != prereq.get('variation'):
                    failed_prereq = prereq
                event = event_factory.new_eval_event(prereq_flag, _context_to_user_dict(context), prereq_res, None, flag)
                state.add_event(event)
            if failed_prereq:
                return {'kind': 'PREREQUISITE_FAILED', 'prerequisiteKey': failed_prereq.get('key')}
        return None

    def _check_targets(self, flag: dict, context: Context) -> Optional[EvaluationDetail]:
        user_targets = flag.get('targets') or []
        context_targets = flag.get('contextTargets') or []
        if len(context_targets) == 0:
            # old-style data has only targets for users
            if len(user_targets) != 0:
                user_context = context.get_individual_context(Context.DEFAULT_KIND)
                if (user_context is None):
                    return None
                key = user_context.key
                for t in user_targets:
                    if key in t['values']:
                        return _target_match_result(flag, t.get('variation'))
            return None
        for t in context_targets:
            kind = t.get('contextKind') or Context.DEFAULT_KIND
            var = t['variation']
            actual_context = context.get_individual_context(kind)
            if actual_context is None:
                continue
            key = actual_context.key
            if kind == Context.DEFAULT_KIND:
                for ut in user_targets:
                    if ut['variation'] == var:
                        if key in ut['values']:
                            return _target_match_result(flag, var)
                        break
                continue
            if key in t['values']:
                return _target_match_result(flag, var)
        return None

    def _rule_matches_context(self, rule: dict, context: Context, state: EvalResult) -> bool:
        for clause in rule.get('clauses') or []:
            if clause.get('attribute') is not None:
                if not self._clause_matches_context(clause, context, state):
                    return False
        return True

    def _clause_matches_context(self, clause: dict, context: Context, state: EvalResult) -> bool:
        op = clause['op']
        if op == 'segmentMatch':
            for seg_key in clause.get('values') or []:
                segment = self.__get_segment(seg_key)
                if segment is not None and self._segment_matches_context(segment, context, state):
                    return _maybe_negate(clause, True)
            return _maybe_negate(clause, False)
        
        attr = clause.get('attribute')
        if attr is None:
            return False
        if attr == 'kind':
            return _maybe_negate(clause, _match_clause_by_kind(clause, context))
        actual_context = context.get_individual_context(clause.get('contextKind') or Context.DEFAULT_KIND)
        if actual_context is None:
            return False
        context_value = actual_context.get(attr)
        if context_value is None:
            return False
        clause_values = clause.get('values') or []
        
        # is the attr an array?
        if isinstance(context_value, (list, tuple)):
            for v in context_value:
                if _match_single_context_value(op, v, clause_values):
                    return _maybe_negate(clause, True)
            return _maybe_negate(clause, False)
        return _maybe_negate(clause, _match_single_context_value(op, context_value, clause_values))

    def _segment_matches_context(self, segment: dict, context: Context, state: EvalResult) -> bool:
        if segment.get('unbounded', False):
            return self._big_segment_match_context(segment, context, state)
        return self._simple_segment_match_context(segment, context, state, True)

    def _simple_segment_match_context(self, segment: dict, context: Context, state: EvalResult, use_includes_and_excludes: bool) -> bool:
        key = context.key
        if key is not None:
            if use_includes_and_excludes:
                if key in segment.get('included', []):
                    return True
                if key in segment.get('excluded', []):
                    return False
            for rule in segment.get('rules', []):
                if self._segment_rule_matches_context(rule, context, state, segment['key'], segment.get('salt', '')):
                    return True
        return False

    def _segment_rule_matches_context(self, rule: dict, context: Context, state: EvalResult, segment_key: str, salt: str) -> bool:
        for clause in rule.get('clauses') or []:
            if not self._clause_matches_context(clause, context, state):
                return False

        # If the weight is absent, this rule matches
        if 'weight' not in rule or rule['weight'] is None:
            return True

        # All of the clauses are met. See if the context buckets in
        bucket_by = 'key' if rule.get('bucketBy') is None else rule['bucketBy']
        bucket = _bucket_context(None, context, segment_key, salt, bucket_by)
        weight = rule['weight'] / 100000.0
        return bucket < weight

    def _big_segment_match_context(self, segment: dict, context: Context, state: EvalResult) -> bool:
        generation = segment.get('generation', None)
        if generation is None:
            # Big segment queries can only be done if the generation is known. If it's unset,
            # that probably means the data store was populated by an older SDK that doesn't know
            # about the generation property and therefore dropped it from the JSON data. We'll treat
            # that as a "not configured" condition.
            state.big_segments_status = BigSegmentsStatus.NOT_CONFIGURED
            return False
        if state.big_segments_status is None:
            result = self.__get_big_segments_membership(context.key)
            state.big_segments_membership, state.big_segments_status = result
        segment_ref = _make_big_segment_ref(segment)
        membership = state.big_segments_membership
        included = None if membership is None else membership.get(segment_ref, None)
        if included is not None:
            return included
        return self._simple_segment_match_context(segment, context, state, False)


# The following functions are declared outside Evaluator because they do not depend on any
# of Evaluator's state.

def _get_variation(flag: dict, variation: int, reason: dict) -> EvaluationDetail:
    vars = flag.get('variations') or []
    if variation < 0 or variation >= len(vars):
        return EvaluationDetail(None, None, error_reason('MALFORMED_FLAG'))
    return EvaluationDetail(vars[variation], variation, reason)

def _get_off_value(flag: dict, reason: dict) -> EvaluationDetail:
    off_var = flag.get('offVariation')
    if off_var is None:
        return EvaluationDetail(None, None, reason)
    return _get_variation(flag, off_var, reason)

def _get_value_for_variation_or_rollout(flag: dict, vr: dict, context: Context, reason: dict) -> EvaluationDetail:
    index, inExperiment = _variation_index_for_context(flag, vr, context)
    if index is None:
        return EvaluationDetail(None, None, error_reason('MALFORMED_FLAG'))
    if inExperiment:
        reason['inExperiment'] = inExperiment
    return _get_variation(flag, index, reason)

def _variation_index_for_context(feature: dict, rule: dict, context: Context) -> Tuple[Optional[int], bool]:
    if rule.get('variation') is not None:
        return (rule['variation'], False)

    rollout = rule.get('rollout')
    if rollout is None:
        return (None, False)
    variations = rollout.get('variations')
    seed = rollout.get('seed')
    if variations is not None and len(variations) > 0:
        bucket_by = 'key'
        if rollout.get('bucketBy') is not None:
            bucket_by = rollout['bucketBy']
        bucket = _bucket_context(seed, context, feature['key'], feature['salt'], bucket_by)
        is_experiment = rollout.get('kind') == 'experiment'
        sum = 0.0
        for wv in variations:
            sum += wv.get('weight', 0.0) / 100000.0
            if bucket < sum:
                is_experiment_partition = is_experiment and not wv.get('untracked')
                return (wv.get('variation'), is_experiment_partition)

        # The context's bucket value was greater than or equal to the end of the last bucket. This could happen due
        # to a rounding error, or due to the fact that we are scaling to 100000 rather than 99999, or the flag
        # data could contain buckets that don't actually add up to 100000. Rather than returning an error in
        # this case (or changing the scaling, which would potentially change the results for *all* contexts), we
        # will simply put the context in the last bucket.
        is_experiment_partition = is_experiment and not variations[-1].get('untracked')
        return (variations[-1].get('variation'), is_experiment_partition)

    return (None, False)

def _bucket_context(seed, context, key, salt, bucket_by) -> float:
    clause_value = context.get(bucket_by or 'key')
    if clause_value is None:
        return 0.0
    bucket_by_value = _bucketable_string_value(clause_value)
    if bucket_by_value is None:
        return 0.0

    id_hash = clause_value
    if context.get('secondary') is not None:
        id_hash = id_hash + '.' + context.get('secondary')

    if seed is not None:
        prefix = str(seed)
    else:
        prefix = '%s.%s' % (key, salt)

    hash_key = '%s.%s' % (prefix, id_hash)
    hash_val = int(hashlib.sha1(hash_key.encode('utf-8')).hexdigest()[:15], 16)
    result = hash_val / __LONG_SCALE__
    return result

def _bucketable_string_value(u_value) -> Optional[str]:
    if isinstance(u_value, bool):
        return None
    elif isinstance(u_value, (str, int)):
        return str(u_value)

    return None

def _match_single_context_value(op: str, context_value: Any, values: List[Any]) -> bool:
    op_fn = operators.ops.get(op)
    if op_fn is None:
        return False
    for v in values:
        if op_fn(context_value, v):
            return True
    return False

def _match_clause_by_kind(clause: dict, context: Context) -> bool:
    # If attribute is "kind", then we treat operator and values as a match expression against a list
    # of all individual kinds in the context. That is, for a multi-kind context with kinds of "org"
    # and "user", it is a match if either of those strings is a match with Operator and Values.
    op = clause['op']
    for i in range(context.individual_context_count):
        c = context.get_individual_context(i)
        if c is not None and _match_single_context_value(op, c.kind, clause.get('values') or []):
            return True
    return False

def _maybe_negate(clause: dict, val: bool) -> bool:
    if clause.get('negate', False) is True:
        return not val
    return val

def _make_big_segment_ref(segment: dict) -> str:
    # The format of Big Segment references is independent of what store implementation is being
    # used; the store implementation receives only this string and does not know the details of
    # the data model. The Relay Proxy will use the same format when writing to the store.
    return "%s.g%d" % (segment.get('key', ''), segment.get('generation', 0))

def _target_match_result(flag: dict, var: int) -> EvaluationDetail:
    return _get_variation(flag, var, {'kind': 'TARGET_MATCH'})

def error_reason(error_kind: str) -> dict:
    return {'kind': 'ERROR', 'errorKind': error_kind}
