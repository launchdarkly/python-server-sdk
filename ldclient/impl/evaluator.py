from ldclient import operators
from ldclient.context import Context
from ldclient.evaluation import BigSegmentsStatus, EvaluationDetail
from ldclient.impl.event_factory import _EventFactory
from ldclient.util import stringify_attrs

from collections import namedtuple
import hashlib
import logging
from typing import Callable, Optional, Tuple

# For consistency with past logging behavior, we are pretending that the evaluation logic still lives in
# the ldclient.evaluation module.
log = logging.getLogger('ldclient.flag')

__LONG_SCALE__ = float(0xFFFFFFFFFFFFFFF)

__BUILTINS__ = ["key", "secondary", "ip", "country", "email",
                "firstName", "lastName", "avatar", "name", "anonymous"]


# EvalResult is used internally to hold the EvaluationDetail result of an evaluation along with
# other side effects that are not exposed to the application, such as events generated by
# prerequisite evaluations, and the cached state of any Big Segments query that we may have
# ended up having to do for the context.
class EvalResult:
    def __init__(self):
        self.detail = None
        self.events = None
        self.big_segments_status = None
        self.big_segments_membership = None

    def add_event(self, event):
        if self.events is None:
            self.events = []
        self.events.append(event)


class Evaluator:
    """
    Encapsulates the feature flag evaluation logic. The Evaluator has no knowledge of the rest of the SDK environment;
    if it needs to retrieve flags or segments that are referenced by a flag, it does so through a read-only interface
    that is provided in the constructor. It also produces feature events as appropriate for any referenced prerequisite
    flags, but does not send them.
    """
    def __init__(
        self,
        get_flag: Callable[[str], Optional[dict]],
        get_segment: Callable[[str], Optional[dict]],
        get_big_segments_membership: Callable[[str], Tuple[Optional[dict], str]]
    ):
        """
        :param get_flag: function provided by LDClient that takes a flag key and returns either the flag or None
        :param get_segment: same as get_flag but for segments
        :param get_big_segments_membership: takes a context key (not a context hash) and returns a tuple of
            (membership, status) where membership is as defined in BigSegmentStore, and status is one
            of the BigSegmentStoreStatus constants
        """
        self.__get_flag = get_flag
        self.__get_segment = get_segment
        self.__get_big_segments_membership = get_big_segments_membership

    def evaluate(self, flag: dict, context: Context, event_factory: _EventFactory) -> EvalResult:
        state = EvalResult()
        state.detail = self._evaluate(flag, context, state, event_factory)
        if state.big_segments_status is not None:
            state.detail.reason['bigSegmentsStatus'] = state.big_segments_status
        return state

    def _evaluate(self, flag: dict, context: Context, state: EvalResult, event_factory: _EventFactory):
        if not flag.get('on', False):
            return _get_off_value(flag, {'kind': 'OFF'})

        prereq_failure_reason = self._check_prerequisites(flag, context, state, event_factory)
        if prereq_failure_reason is not None:
            return _get_off_value(flag, prereq_failure_reason)

        # Check to see if any context targets match:
        for target in flag.get('targets') or []:
            for value in target.get('values') or []:
                if value == context.key:
                    return _get_variation(flag, target.get('variation'), {'kind': 'TARGET_MATCH'})

        # Now walk through the rules to see if any match
        for index, rule in enumerate(flag.get('rules') or []):
            if self._rule_matches_context(rule, context, state):
                return _get_value_for_variation_or_rollout(flag, rule, context,
                    {'kind': 'RULE_MATCH', 'ruleIndex': index, 'ruleId': rule.get('id')})

        # Walk through fallthrough and see if it matches
        if flag.get('fallthrough') is not None:
            return _get_value_for_variation_or_rollout(flag, flag['fallthrough'], context, {'kind': 'FALLTHROUGH'})

    def _check_prerequisites(self, flag: dict, context: Context, state: EvalResult, event_factory: _EventFactory):
        failed_prereq = None
        prereq_res = None
        for prereq in flag.get('prerequisites') or []:
            prereq_flag = self.__get_flag(prereq.get('key'))
            if prereq_flag is None:
                log.warning("Missing prereq flag: " + prereq.get('key'))
                failed_prereq = prereq
            else:
                prereq_res = self._evaluate(prereq_flag, context, state, event_factory)
                # Note that if the prerequisite flag is off, we don't consider it a match no matter what its
                # off variation was. But we still need to evaluate it in order to generate an event.
                if (not prereq_flag.get('on', False)) or prereq_res.variation_index != prereq.get('variation'):
                    failed_prereq = prereq
                event = event_factory.new_eval_event(prereq_flag, context, prereq_res, None, flag)
                state.add_event(event)
            if failed_prereq:
                return {'kind': 'PREREQUISITE_FAILED', 'prerequisiteKey': failed_prereq.get('key')}
        return None

    def _rule_matches_context(self, rule: dict, context: Context, state: EvalResult):
        for clause in rule.get('clauses') or []:
            if clause.get('attribute') is not None:
                if not self._clause_matches_context(clause, context, state):
                    return False
        return True

    def _clause_matches_context(self, clause: dict, context: Context, state: EvalResult):
        if clause.get('op') == 'segmentMatch':
            for seg_key in clause.get('values') or []:
                segment = self.__get_segment(seg_key)
                if segment is not None and self._segment_matches_context(segment, context, state):
                    return _maybe_negate(clause, True)
            return _maybe_negate(clause, False)
        else:
            return _clause_matches_context_no_segments(clause, context)

    def _segment_matches_context(self, segment: dict, context: Context, state: EvalResult):
        if segment.get('unbounded', False):
            return self._big_segment_match_context(segment, context, state)
        return _simple_segment_match_context(segment, context, True)

    def _big_segment_match_context(self, segment: dict, context: Context, state: EvalResult):
        generation = segment.get('generation', None)
        if generation is None:
            # Big segment queries can only be done if the generation is known. If it's unset,
            # that probably means the data store was populated by an older SDK that doesn't know
            # about the generation property and therefore dropped it from the JSON data. We'll treat
            # that as a "not configured" condition.
            state.big_segments_status = BigSegmentsStatus.NOT_CONFIGURED
            return False
        if state.big_segments_status is None:
            result = self.__get_big_segments_membership(context.key)
            state.big_segments_membership, state.big_segments_status = result
        segment_ref = _make_big_segment_ref(segment)
        membership = state.big_segments_membership
        included = None if membership is None else membership.get(segment_ref, None)
        if included is not None:
            return included
        return _simple_segment_match_context(segment, context, False)


# The following functions are declared outside Evaluator because they do not depend on any
# of Evaluator's state.

def _get_variation(flag, variation, reason):
    vars = flag.get('variations') or []
    if variation < 0 or variation >= len(vars):
        return EvaluationDetail(None, None, error_reason('MALFORMED_FLAG'))
    return EvaluationDetail(vars[variation], variation, reason)

def _get_off_value(flag, reason):
    off_var = flag.get('offVariation')
    if off_var is None:
        return EvaluationDetail(None, None, reason)
    return _get_variation(flag, off_var, reason)

def _get_value_for_variation_or_rollout(flag, vr, context, reason):
    index, inExperiment = _variation_index_for_context(flag, vr, context)
    if index is None:
        return EvaluationDetail(None, None, error_reason('MALFORMED_FLAG'))
    if inExperiment:
        reason['inExperiment'] = inExperiment
    return _get_variation(flag, index, reason)

def _variation_index_for_context(feature, rule, context):
    if rule.get('variation') is not None:
        return (rule['variation'], False)

    rollout = rule.get('rollout')
    if rollout is None:
        return (None, False)
    variations = rollout.get('variations')
    seed = rollout.get('seed')
    if variations is not None and len(variations) > 0:
        bucket_by = 'key'
        if rollout.get('bucketBy') is not None:
            bucket_by = rollout['bucketBy']
        bucket = _bucket_context(seed, context, feature['key'], feature['salt'], bucket_by)
        is_experiment = rollout.get('kind') == 'experiment'
        sum = 0.0
        for wv in variations:
            sum += wv.get('weight', 0.0) / 100000.0
            if bucket < sum:
                is_experiment_partition = is_experiment and not wv.get('untracked')
                return (wv.get('variation'), is_experiment_partition)

        # The context's bucket value was greater than or equal to the end of the last bucket. This could happen due
        # to a rounding error, or due to the fact that we are scaling to 100000 rather than 99999, or the flag
        # data could contain buckets that don't actually add up to 100000. Rather than returning an error in
        # this case (or changing the scaling, which would potentially change the results for *all* contexts), we
        # will simply put the context in the last bucket.
        is_experiment_partition = is_experiment and not variations[-1].get('untracked')
        return (variations[-1].get('variation'), is_experiment_partition)

    return (None, False)

def _bucket_context(seed, context, key, salt, bucket_by):
    clause_value = context.get(bucket_by or 'key')
    if clause_value is None:
        return 0.0
    bucket_by_value = _bucketable_string_value(clause_value)
    if bucket_by_value is None:
        return 0.0

    id_hash = clause_value
    if context.get('secondary') is not None:
        id_hash = id_hash + '.' + context.get('secondary')

    if seed is not None:
        prefix = str(seed)
    else:
        prefix = '%s.%s' % (key, salt)

    hash_key = '%s.%s' % (prefix, id_hash)
    hash_val = int(hashlib.sha1(hash_key.encode('utf-8')).hexdigest()[:15], 16)
    result = hash_val / __LONG_SCALE__
    return result

def _bucketable_string_value(u_value):
    if isinstance(u_value, bool):
        return None
    elif isinstance(u_value, (str, int)):
        return str(u_value)

    return None

def _clause_matches_context_no_segments(clause, context):
    attr = clause.get('attribute')
    if attr is None:
        return False
    context_value = context.get(attr)
    if context_value is None:
        return None
    # is the attr an array?
    op_fn = operators.ops[clause['op']]
    if isinstance(context_value, (list, tuple)):
        for v in context_value:
            if _match_any(op_fn, v, clause.get('values') or []):
                return _maybe_negate(clause, True)
        return _maybe_negate(clause, False)
    else:
        return _maybe_negate(clause, _match_any(op_fn, context_value, clause.get('values') or []))

def _simple_segment_match_context(segment, context, use_includes_and_excludes):
    key = context.key
    if key is not None:
        if use_includes_and_excludes:
            if key in segment.get('included', []):
                return True
            if key in segment.get('excluded', []):
                return False
        for rule in segment.get('rules', []):
            if _segment_rule_matches_context(rule, context, segment.get('key'), segment.get('salt')):
                return True
    return False

def _segment_rule_matches_context(rule, context, segment_key, salt):
    for clause in rule.get('clauses') or []:
        if not _clause_matches_context_no_segments(clause, context):
            return False

    # If the weight is absent, this rule matches
    if 'weight' not in rule or rule['weight'] is None:
        return True

    # All of the clauses are met. See if the context buckets in
    bucket_by = 'key' if rule.get('bucketBy') is None else rule['bucketBy']
    bucket = _bucket_context(None, context, segment_key, salt, bucket_by)
    weight = rule['weight'] / 100000.0
    return bucket < weight

def _match_any(op_fn, u, vals):
    for v in vals:
        if op_fn(u, v):
            return True
    return False

def _maybe_negate(clause, val):
    if clause.get('negate', False) is True:
        return not val
    return val

def _make_big_segment_ref(segment: dict) -> str:
    # The format of Big Segment references is independent of what store implementation is being
    # used; the store implementation receives only this string and does not know the details of
    # the data model. The Relay Proxy will use the same format when writing to the store.
    return "%s.g%d" % (segment.get('key', ''), segment.get('generation', 0))

def error_reason(error_kind: str) -> dict:
    return {'kind': 'ERROR', 'errorKind': error_kind}
